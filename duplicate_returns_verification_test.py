#!/usr/bin/env python3
"""
DUPLICATE RETURNS ISSUE VERIFICATION TEST

This test specifically verifies that the duplicate returns issue has been resolved:
1. Backend deduplication logic in returns_controller_enhanced.py
2. Database cleanup removing duplicate records for tenant-rms34
3. Clean data structure with unique entries
4. Verify deduplication logic is working in the API

Test Focus: GET /api/returns/ for tenant-rms34
"""

import asyncio
import aiohttp
import json
from datetime import datetime
from typing import Dict, List, Any, Set
import uuid

# Configuration
BACKEND_URL = "https://returnflow-4.preview.emergentagent.com/api"
TEST_TENANT_ID = "tenant-rms34"  # Specific tenant mentioned in the issue
TEST_HEADERS = {
    "Content-Type": "application/json",
    "X-Tenant-Id": TEST_TENANT_ID
}

class DuplicateReturnsVerificationTest:
    def __init__(self):
        self.session = None
        self.test_results = []
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def log_test(self, test_name: str, success: bool, details: str = "", response_data: Any = None):
        """Log test result"""
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status} {test_name}")
        if details:
            print(f"   {details}")
        if not success and response_data:
            print(f"   Response: {json.dumps(response_data, indent=2)}")
        
        self.test_results.append({
            "test": test_name,
            "success": success,
            "details": details,
            "response": response_data
        })
    
    async def make_request(self, method: str, endpoint: str, data: Dict = None, headers: Dict = None) -> tuple:
        """Make HTTP request and return (success, response_data, status_code)"""
        try:
            url = f"{BACKEND_URL}{endpoint}"
            request_headers = {**TEST_HEADERS, **(headers or {})}
            
            if method.upper() == "GET":
                async with self.session.get(url, headers=request_headers) as response:
                    response_data = await response.json()
                    return response.status < 400, response_data, response.status
            elif method.upper() == "POST":
                async with self.session.post(url, json=data, headers=request_headers) as response:
                    response_data = await response.json()
                    return response.status < 400, response_data, response.status
                    
        except Exception as e:
            return False, {"error": str(e)}, 500
    
    async def test_backend_health(self):
        """Test if backend is accessible"""
        print("\nüè• Testing Backend Health...")
        
        success, health_data, status = await self.make_request("GET", "/health", headers={})
        if success:
            self.log_test("Backend Health Check", True, "Backend is accessible and healthy")
            return True
        else:
            self.log_test("Backend Health Check", False, f"Backend not accessible: {status}")
            return False
    
    async def test_tenant_rms34_returns_api(self):
        """Test GET /api/returns/ specifically for tenant-rms34"""
        print("\nüéØ Testing Returns API for tenant-rms34...")
        
        # Test 1: Basic API accessibility
        success, response, status = await self.make_request("GET", "/returns/")
        
        if not success:
            self.log_test("Returns API Accessibility", False, f"API not accessible. Status: {status}, Response: {response}")
            return False
        
        self.log_test("Returns API Accessibility", True, f"API accessible, status: {status}")
        
        # Test 2: Response structure validation
        if not isinstance(response, dict):
            self.log_test("Response Structure", False, "Response is not a dictionary")
            return False
        
        required_fields = ["returns", "pagination"]
        missing_fields = [field for field in required_fields if field not in response]
        
        if missing_fields:
            self.log_test("Response Structure", False, f"Missing required fields: {missing_fields}")
            return False
        
        self.log_test("Response Structure", True, "Response has required fields: returns, pagination")
        
        # Test 3: Returns data validation
        returns_data = response.get("returns", [])
        if not isinstance(returns_data, list):
            self.log_test("Returns Data Type", False, "Returns field is not a list")
            return False
        
        self.log_test("Returns Data Type", True, f"Returns is a list with {len(returns_data)} items")
        
        return returns_data, response
    
    async def test_duplicate_detection(self, returns_data: List[Dict]):
        """Test for duplicate returns based on order_id + customer_email combinations"""
        print("\nüîç Testing Duplicate Detection...")
        
        if not returns_data:
            self.log_test("Duplicate Detection", True, "No returns data to check for duplicates")
            return
        
        # Track combinations of order_id + customer_email
        combinations_seen = {}
        duplicates_found = []
        
        for return_item in returns_data:
            order_id = return_item.get("order_id", "")
            customer_email = return_item.get("customer_email", "")
            return_id = return_item.get("id", "")
            
            combination_key = f"{order_id}:{customer_email}"
            
            if combination_key in combinations_seen:
                # Duplicate found!
                duplicates_found.append({
                    "combination": combination_key,
                    "existing_return": combinations_seen[combination_key],
                    "duplicate_return": {
                        "id": return_id,
                        "order_id": order_id,
                        "customer_email": customer_email,
                        "created_at": return_item.get("created_at", ""),
                        "status": return_item.get("status", "")
                    }
                })
            else:
                combinations_seen[combination_key] = {
                    "id": return_id,
                    "order_id": order_id,
                    "customer_email": customer_email,
                    "created_at": return_item.get("created_at", ""),
                    "status": return_item.get("status", "")
                }
        
        # Test results
        if duplicates_found:
            self.log_test("Duplicate Detection", False, 
                         f"Found {len(duplicates_found)} duplicate return combinations", 
                         duplicates_found)
            
            # Log specific duplicates for debugging
            for dup in duplicates_found:
                print(f"   üö® DUPLICATE: {dup['combination']}")
                print(f"      Existing: {dup['existing_return']['id']} (created: {dup['existing_return']['created_at']})")
                print(f"      Duplicate: {dup['duplicate_return']['id']} (created: {dup['duplicate_return']['created_at']})")
            
            return False
        else:
            self.log_test("Duplicate Detection", True, 
                         f"No duplicates found! All {len(returns_data)} returns have unique order_id + customer_email combinations")
            return True
    
    async def test_specific_order_1001_duplicates(self, returns_data: List[Dict]):
        """Test specifically for order 1001 + shashankshekharofficial15@gmail.com duplicates mentioned in the issue"""
        print("\nüéØ Testing Specific Order 1001 Duplicates...")
        
        target_order_id = "1001"
        target_email = "shashankshekharofficial15@gmail.com"
        
        matching_returns = []
        for return_item in returns_data:
            if (return_item.get("order_id") == target_order_id and 
                return_item.get("customer_email") == target_email):
                matching_returns.append(return_item)
        
        if len(matching_returns) == 0:
            self.log_test("Order 1001 Specific Test", True, 
                         f"No returns found for order {target_order_id} + {target_email} (duplicates successfully cleaned up)")
        elif len(matching_returns) == 1:
            self.log_test("Order 1001 Specific Test", True, 
                         f"Found exactly 1 return for order {target_order_id} + {target_email} (duplicates successfully resolved)")
            print(f"   Return ID: {matching_returns[0].get('id')}")
            print(f"   Status: {matching_returns[0].get('status')}")
            print(f"   Created: {matching_returns[0].get('created_at')}")
        else:
            self.log_test("Order 1001 Specific Test", False, 
                         f"Found {len(matching_returns)} returns for order {target_order_id} + {target_email} - duplicates still exist!",
                         matching_returns)
            return False
        
        return True
    
    async def test_data_quality_checks(self, returns_data: List[Dict]):
        """Test data quality and completeness"""
        print("\nüìä Testing Data Quality...")
        
        if not returns_data:
            self.log_test("Data Quality", True, "No data to validate")
            return
        
        # Test 1: Required fields presence
        required_fields = ["id", "order_id", "customer_email", "status", "created_at"]
        incomplete_returns = []
        
        for return_item in returns_data:
            missing_fields = [field for field in required_fields if not return_item.get(field)]
            if missing_fields:
                incomplete_returns.append({
                    "return_id": return_item.get("id", "unknown"),
                    "missing_fields": missing_fields
                })
        
        if incomplete_returns:
            self.log_test("Data Completeness", False, 
                         f"{len(incomplete_returns)} returns have missing required fields",
                         incomplete_returns[:3])  # Show first 3 examples
        else:
            self.log_test("Data Completeness", True, 
                         f"All {len(returns_data)} returns have required fields")
        
        # Test 2: Valid return IDs (should be UUIDs)
        invalid_ids = []
        for return_item in returns_data:
            return_id = return_item.get("id", "")
            try:
                uuid.UUID(return_id)
            except ValueError:
                invalid_ids.append(return_id)
        
        if invalid_ids:
            self.log_test("Return ID Format", False, 
                         f"{len(invalid_ids)} returns have invalid UUID format",
                         invalid_ids[:5])
        else:
            self.log_test("Return ID Format", True, 
                         "All return IDs are valid UUIDs")
        
        # Test 3: Valid statuses
        valid_statuses = ["REQUESTED", "APPROVED", "DENIED", "PROCESSING", "COMPLETED", "ARCHIVED"]
        invalid_statuses = []
        
        for return_item in returns_data:
            status = return_item.get("status", "").upper()
            if status and status not in valid_statuses:
                invalid_statuses.append({
                    "return_id": return_item.get("id"),
                    "invalid_status": status
                })
        
        if invalid_statuses:
            self.log_test("Status Validation", False, 
                         f"{len(invalid_statuses)} returns have invalid statuses",
                         invalid_statuses[:3])
        else:
            self.log_test("Status Validation", True, 
                         "All return statuses are valid")
    
    async def test_deduplication_logic_effectiveness(self, returns_data: List[Dict]):
        """Test the effectiveness of the deduplication logic"""
        print("\n‚öôÔ∏è Testing Deduplication Logic Effectiveness...")
        
        # Test 1: Count unique combinations vs total returns
        unique_combinations = set()
        for return_item in returns_data:
            order_id = return_item.get("order_id", "")
            customer_email = return_item.get("customer_email", "")
            unique_combinations.add(f"{order_id}:{customer_email}")
        
        total_returns = len(returns_data)
        unique_combinations_count = len(unique_combinations)
        
        if total_returns == unique_combinations_count:
            self.log_test("Deduplication Effectiveness", True, 
                         f"Perfect deduplication: {total_returns} returns = {unique_combinations_count} unique combinations")
        else:
            self.log_test("Deduplication Effectiveness", False, 
                         f"Deduplication failed: {total_returns} returns but only {unique_combinations_count} unique combinations")
        
        # Test 2: Check if the most recent return is kept for each combination
        combination_returns = {}
        for return_item in returns_data:
            order_id = return_item.get("order_id", "")
            customer_email = return_item.get("customer_email", "")
            combination_key = f"{order_id}:{customer_email}"
            
            if combination_key not in combination_returns:
                combination_returns[combination_key] = []
            combination_returns[combination_key].append(return_item)
        
        # Since deduplication should ensure only one return per combination,
        # each combination should have exactly one return
        multi_return_combinations = {k: v for k, v in combination_returns.items() if len(v) > 1}
        
        if multi_return_combinations:
            self.log_test("Single Return Per Combination", False, 
                         f"{len(multi_return_combinations)} combinations have multiple returns",
                         list(multi_return_combinations.keys())[:3])
        else:
            self.log_test("Single Return Per Combination", True, 
                         "Each order+customer combination has exactly one return")
    
    async def test_pagination_with_deduplication(self):
        """Test that pagination works correctly with deduplication"""
        print("\nüìÑ Testing Pagination with Deduplication...")
        
        # Test different page sizes to ensure deduplication works across pages
        page_sizes = [5, 10, 25]
        
        for page_size in page_sizes:
            success, response, status = await self.make_request("GET", f"/returns/?pageSize={page_size}&page=1")
            
            if not success:
                self.log_test(f"Pagination (pageSize={page_size})", False, 
                             f"Failed to get paginated results: {status}")
                continue
            
            returns_data = response.get("returns", [])
            pagination = response.get("pagination", {})
            
            # Check if pagination info is correct
            expected_page_size = min(page_size, pagination.get("total", 0))
            actual_returns = len(returns_data)
            
            if actual_returns <= expected_page_size:
                self.log_test(f"Pagination (pageSize={page_size})", True, 
                             f"Returned {actual_returns} returns (expected ‚â§ {expected_page_size})")
            else:
                self.log_test(f"Pagination (pageSize={page_size})", False, 
                             f"Returned {actual_returns} returns (expected ‚â§ {expected_page_size})")
            
            # Check for duplicates in this page
            await self.test_duplicate_detection(returns_data)
    
    async def test_database_cleanup_verification(self):
        """Verify that database cleanup was successful"""
        print("\nüóÑÔ∏è Testing Database Cleanup Verification...")
        
        # Get all returns for tenant-rms34 to verify cleanup
        success, response, status = await self.make_request("GET", "/returns/?pageSize=100")
        
        if not success:
            self.log_test("Database Cleanup Verification", False, 
                         f"Could not retrieve returns for cleanup verification: {status}")
            return
        
        returns_data = response.get("returns", [])
        total_returns = response.get("pagination", {}).get("total", 0)
        
        # According to the issue, there should be 4 unique returns after cleanup
        # (originally 15 returns with 11 duplicates removed = 4 remaining)
        expected_returns_after_cleanup = 4
        
        if total_returns == expected_returns_after_cleanup:
            self.log_test("Database Cleanup Verification", True, 
                         f"Database cleanup successful: exactly {total_returns} returns remaining (expected {expected_returns_after_cleanup})")
        elif total_returns < expected_returns_after_cleanup:
            self.log_test("Database Cleanup Verification", True, 
                         f"Database cleanup successful: {total_returns} returns remaining (‚â§ {expected_returns_after_cleanup} expected)")
        else:
            self.log_test("Database Cleanup Verification", False, 
                         f"Database cleanup may be incomplete: {total_returns} returns found (expected ‚â§ {expected_returns_after_cleanup})")
        
        return returns_data
    
    async def run_verification_tests(self):
        """Run all duplicate returns verification tests"""
        print("üöÄ Starting Duplicate Returns Issue Verification")
        print("=" * 60)
        print(f"Target Tenant: {TEST_TENANT_ID}")
        print(f"Backend URL: {BACKEND_URL}")
        print("=" * 60)
        
        # Test 1: Backend health
        if not await self.test_backend_health():
            print("‚ùå Backend not accessible. Stopping tests.")
            return
        
        # Test 2: Database cleanup verification
        returns_data = await self.test_database_cleanup_verification()
        
        # Test 3: Returns API functionality
        api_result = await self.test_tenant_rms34_returns_api()
        if not api_result:
            print("‚ùå Returns API not working. Stopping tests.")
            return
        
        returns_data, full_response = api_result
        
        # Test 4: Duplicate detection
        await self.test_duplicate_detection(returns_data)
        
        # Test 5: Specific order 1001 duplicates test
        await self.test_specific_order_1001_duplicates(returns_data)
        
        # Test 6: Data quality checks
        await self.test_data_quality_checks(returns_data)
        
        # Test 7: Deduplication logic effectiveness
        await self.test_deduplication_logic_effectiveness(returns_data)
        
        # Test 8: Pagination with deduplication
        await self.test_pagination_with_deduplication()
        
        # Summary
        self.print_verification_summary()
    
    def print_verification_summary(self):
        """Print verification test summary"""
        print("\n" + "=" * 60)
        print("üìä DUPLICATE RETURNS VERIFICATION SUMMARY")
        print("=" * 60)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results if result["success"])
        failed_tests = total_tests - passed_tests
        
        print(f"Total Tests: {total_tests}")
        print(f"‚úÖ Passed: {passed_tests}")
        print(f"‚ùå Failed: {failed_tests}")
        print(f"Success Rate: {(passed_tests/total_tests*100):.1f}%")
        
        # Overall verification result
        critical_tests = [
            "Duplicate Detection",
            "Order 1001 Specific Test", 
            "Deduplication Effectiveness",
            "Single Return Per Combination"
        ]
        
        critical_failures = [r for r in self.test_results 
                           if not r["success"] and any(ct in r["test"] for ct in critical_tests)]
        
        if critical_failures:
            print(f"\nüö® VERIFICATION RESULT: FAILED")
            print(f"   Critical duplicate issues still exist!")
            print(f"   Failed critical tests: {len(critical_failures)}")
        else:
            print(f"\nüéâ VERIFICATION RESULT: SUCCESS")
            print(f"   Duplicate returns issue has been resolved!")
            print(f"   All critical deduplication tests passed.")
        
        if failed_tests > 0:
            print(f"\n‚ùå FAILED TESTS:")
            for result in self.test_results:
                if not result["success"]:
                    print(f"   ‚Ä¢ {result['test']}: {result['details']}")
        
        print(f"\nüéØ KEY FINDINGS:")
        print(f"   ‚Ä¢ Backend API is accessible and functional")
        print(f"   ‚Ä¢ Deduplication logic is implemented in returns_controller_enhanced.py")
        print(f"   ‚Ä¢ Database cleanup appears to have been executed")
        print(f"   ‚Ä¢ API response structure is correct and complete")
        
        if not critical_failures:
            print(f"   ‚Ä¢ ‚úÖ No duplicate returns detected for tenant-rms34")
            print(f"   ‚Ä¢ ‚úÖ Order 1001 + shashankshekharofficial15@gmail.com duplicates resolved")
            print(f"   ‚Ä¢ ‚úÖ Deduplication logic working effectively")

async def main():
    """Main test execution"""
    async with DuplicateReturnsVerificationTest() as test_suite:
        await test_suite.run_verification_tests()

if __name__ == "__main__":
    asyncio.run(main())